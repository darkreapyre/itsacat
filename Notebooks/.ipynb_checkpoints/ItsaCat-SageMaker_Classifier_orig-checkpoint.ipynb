{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Training and Prediction\n",
    "## Introduction\n",
    "[Amazon SageMaker](https://aws.amazon.com/sagemaker/?sc_channel=PS&sc_campaign=pac_ps_q4&sc_publisher=google&sc_medium=sagemaker_b_pac_search&sc_content=sagemaker_e&sc_detail=aws%20sagemaker&sc_category=sagemaker&sc_segment=webp&sc_matchtype=e&sc_country=US&sc_geo=namer&sc_outcome=pac&s_kwcid=AL!4422!3!245225393502!e!!g!!aws%20sagemaker&ef_id=WL2I0wAAAIRC8xLB:20180418161912:s) is a fully mamnaged platform that enables Data Scientists to build, train and deploy machine learning models at any scale. It provides key services necessary to create and manage a Machine Learning (ML) Pipeline from \"Notebook\" to \"Production\", as highlighted below:\n",
    "\n",
    "<img src=\"images/SageMaker_Workflow.png\" style=\"width:800px;height:200px;\">\n",
    "\n",
    "The following Notebook demonstrates this process by using SageMaker's built-in [Image Classification Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html). To accomplish this, SageMaker's Image Classification Algorithm leverages a commonly used and pre-built model for image classification called __Resnet__ (You can read more about Resnet [here](https://arxiv.org/abs/1512.03385)). It also provides the added feature of leveraging pre-trained weights, thus allowing for [Transfer Learning](https://en.wikipedia.org/wiki/Transfer_learning). A technique used for reducing the time required for training a new model, where instead of training a model from scratch, on e can use a modified pre-trained model and continue training it with a unique dataset. In essense, tranferring the knowledge learned from one model to another.\n",
    "\n",
    "By leveraging this methadology, the Data Scientist doesn't need to expend time to build, train and optmize a custom Image Classification model, as was done in [Demo 2](https://github.com/darkreapyre/itsacat/blob/Demo-2/Notebooks/ItsaCat-Gluon_Codebook.ipynb), but rather simply provide the training data and left SageMaker perform all the heavy lifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 - Using the Notebook instance to understand and Manage the Input Data.\n",
    "The SageMaker Notebook instace is a fully mananged compute instance that runs the Jupyter Notebook application and allows the *Data Scientist* to explore and preprocess the dataset that is used to train the ML model. The Notebook instance can also be thought of as an Integrated Development Environment (IDE) for writting the code for the ML model, training the model as wella as testing/validating the model's performance. For more information on using the SageMaker Notebook Instances, see the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permissions and Environmental Variables\n",
    "\n",
    "The packages that will be needed to prepare the data and train the model are as follows:\n",
    "- [datetime](https://docs.python.org/2/library/datetime.html) provides classes for manipulating dates and times in both simple and complex ways.\n",
    "- [numpy](https://www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](https://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) is used here to test the model on unseen image data at the end.\n",
    "- [boto3](https://pypi.python.org/pypi/boto3) is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.\n",
    "- [json](https://docs.python.org/3/library/json.html) is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript.\n",
    "- [os](https://docs.python.org/3/library/os.html) is a module the provides a portable way of using operating system dependent functionality. Particularly the  environ object is a mapping object representing the environment.\n",
    "- [tarfile](https://docs.python.org/3/library/tarfile.html) is used to read and write tar archives, when extracting the model training results from S3.\n",
    "- [urllib](https://docs.python.org/3/library/urllib.html) is a package with several modeules that are used to work with URL's. The `request` module is used for openning and reading URL's.\n",
    "- [imageio](https://imageio.github.io) for reading and writing image data.\n",
    "- [mxnet](http://mxnet.incubator.apache.org) is a flexable and effecient library for deep learning.\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) is an open source library for training and deploying machine learning models on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import h5py\n",
    "import json\n",
    "import tarfile\n",
    "import datetime\n",
    "import urllib.request\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from mxnet import gluon\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification') #Image Classification Estimator\n",
    "\n",
    "# Helper functions\n",
    "def download(url):\n",
    "    \"\"\"\n",
    "    Downloads the target file from the given URL.\n",
    "    \n",
    "    Arguments:\n",
    "    url -- Full URL to download\n",
    "    \"\"\"\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Build the make_list function\n",
    "def make_lst(data, label, name):\n",
    "    \"\"\"\n",
    "    Make a custom tab separated `lst` file for `im2rec.py`\n",
    "    \n",
    "    Arguments:\n",
    "    data -- Numpy array of image data\n",
    "    label -- \"Truth\" label for image classification\n",
    "    name -- \"train\" or \"test\" data\n",
    "    \"\"\"\n",
    "    # Create local repository for the images based on name\n",
    "    if not os.path.exists('./'+name):\n",
    "        os.mkdir('./'+name)\n",
    "        \n",
    "    # Create the lst file\n",
    "    lst_file = './'+name+'.lst'\n",
    "    \n",
    "    # Iterate through the numpy arrays and save as `.jpg`\n",
    "    # and update the index file\n",
    "    for i in range(len(data)):\n",
    "        img = data[i]\n",
    "        img_name = name+'/'+str(i)+'.jpg'\n",
    "        imageio.imwrite(img_name, img)\n",
    "        with open(lst_file, 'a') as f:\n",
    "            f.write(\"{}\\t{}\\t{}\\n\".format(str(i), str(label[i]), img_name))\n",
    "            f.flush()\n",
    "            f.close()\n",
    "\n",
    "try:\n",
    "    import multiprocessing\n",
    "except ImportError:\n",
    "    multiprocessing = None\n",
    "\n",
    "# Download the tool for creating RecordIO formatted data\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Preparation\n",
    "To train the Neural Network, we are provided with a dataset (`datasets.h5`) containing:\n",
    "- a training set of $m$ images containing cats and non-cats as well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "- a test set of $m$ images containing cats and non-cat as well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "\n",
    ">**Note:** The original dataset was comprised of two separate files, `test_catvnoncat.h5` and `train_catvnoncat.h5`. For the sake of this implementation a single file is used, `datasets.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training and Testing dataset\n",
    "dataset = h5py.File('datasets/datasets.h5', 'r')\n",
    "\n",
    "# Createw the Training and Testing data sets\n",
    "X_train = np.array(dataset['train_set_x'][:])\n",
    "y_train = np.array(dataset['train_set_y'][:])\n",
    "X_test = np.array(dataset['test_set_x'][:])\n",
    "y_test = np.array(dataset['test_set_y'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the cell above, the image training and testing (validation) input data (`train_set_x` and `test_set_x`) are 4-dimensional arrays consiting of $209$ training examoples ($m$) and $50$ testing images. Each image is in turn of height, width and depth (**R**ed, **G**reen **B**lue values) of $64 \\times 64 \\times 3$. Additionally, the dimension for the \"true\" labels (`train_set_y` and `test_set_y`) only show a $209$ and $50$ column structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Dimension: (209, 64, 64, 3)\n",
      "No. Training Examples: 209\n",
      "No. Training Features: 12288\n"
     ]
    }
   ],
   "source": [
    "# Training data set dimensions\n",
    "print(\"Training Data Dimension: {}\".format(X_train.shape))\n",
    "print(\"No. Training Examples: {}\".format(X_train.shape[0]))\n",
    "print(\"No. Training Features: {}\".format(X_train.reshape((-1, 12288)).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Dimension: (50, 64, 64, 3)\n",
      "No. Training Examples: 50\n",
      "No. Training Features: 12288\n"
     ]
    }
   ],
   "source": [
    "# Testing data set dimensions\n",
    "print(\"Training Data Dimension: {}\".format(X_test.shape))\n",
    "print(\"No. Training Examples: {}\".format(X_test.shape[0]))\n",
    "print(\"No. Training Features: {}\".format(X_test.reshape((-1, 12288)).shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SageMaker's built-in Image Classification algorithm requires that the dataset be formatted in [RecordIO](https://mxnet.incubator.apache.org/architecture/note_data_loading.html). RecordIO is an efficient file format that feeds images for model training as a stream, thus allowing for the entire dataset to be loaded either into CPU or GPU memeory and thus vastly iomproving the model training time. Some fo the benefits include:\n",
    "- Storing images in a compact format, which greatly reduces the size of the dataset on the disk.\n",
    "- Packing data together allows continuous reading on the disk.\n",
    "- RecordIO has a simple way to partition, simplifying the distriburtion of training data when leveraging distributed training.\n",
    "\n",
    "Since the Training and Testing data sets are currently stored as Numpy arrays, they will need to be converted to native `.jpg` images and then converted to RecordIO format before uploading them to S3.\n",
    "\n",
    "However, the associated metadata (i.e. the classification label of the image) needs to be captured along with the image file when converting to the RecordIO format. In order to accomplish this, a `.lst` file needs to be created that captures the metadata of the image and it's associated label.\n",
    "\n",
    "A `.lst` file is a tab-separated file with three columns that contains a list of image files. The first column specifies the image index, the second column specifies the class label index for the image, and the third column specifies the relative path of the image file. The image index in the first column should be unique across all of the images. The following code cell leverages the `make_lst()` helper function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output of the `train.lst` file:\n",
      "\n",
      "0\t0\ttrain/0.jpg\n",
      "1\t0\ttrain/1.jpg\n",
      "2\t1\ttrain/2.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create `train.lst`\n",
    "make_lst(X_train, y_train, name='train')\n",
    "\n",
    "# Create `test.lst`\n",
    "make_lst(X_test, y_test, name='test')\n",
    "\n",
    "# View the output of the training `.lst` file\n",
    "print(\"Sample output of the `train.lst` file:\\n\")\n",
    "!head -n 3 ./train.lst > example.lst\n",
    "f = open('example.lst','r')\n",
    "lst_content = f.read()\n",
    "print(lst_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the the associated image metadata has been captures, the RecordIO files can be built. This is a done by leveraging the [im2rec](https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py) tool that has already been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/itsacat/Notebooks/train.lst in /home/ec2-user/SageMaker/itsacat/Notebooks\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.00029468536376953125  count: 0\n",
      "Creating .rec file from /home/ec2-user/SageMaker/itsacat/Notebooks/test.lst in /home/ec2-user/SageMaker/itsacat/Notebooks\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.0002923011779785156  count: 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Convert training and validation images to `.rec`\n",
    "python im2rec.py ./train.lst ./ --quality 100 --pass-through\n",
    "python im2rec.py ./test.lst ./ --quality 100 --pass-through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Upload\n",
    "In order for *SageMaker* to execute the training and validation process on the Input Data, the data needs to be uploaded to S3. *SageMaker* provides the handy function, `upload_data()`, to upload the Numpy data to a default (or specific) location. If not already created, the function will create an S3 bucket. The resulting S3 bucket will also store the various training and testing output that will be used for creating production *Endpoints* and *Analysis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: sagemaker-us-west-2-500842391574\n"
     ]
    }
   ],
   "source": [
    "# Upload the Training and Testing Data to S3\n",
    "training_data = sagemaker_session.upload_data(path='./train.rec', key_prefix='train')\n",
    "testing__data = sagemaker_session.upload_data(path='./test.rec', key_prefix='test')\n",
    "bucket = training_data.split('/')[2]\n",
    "print(\"S3 Bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 - Training the Classifier as a SageMaker Training Job.\n",
    "### Training Function\n",
    "The *Training Function*, `model.py`, contains the instructions that *SageMaker* needs to:\n",
    "1. Load the Input training and validation data sets from S3; `get_data()`.\n",
    "2. Pre-process, \"vectorize\" and scale the image data to be processed by the Neural Network; `transform()`.\n",
    "3. Train the model and validate the prediction accuracy of the proposed Neural Network model on the Input data; `train()`.\n",
    "4. Save the model and training results to S3; `save()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = 50\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,64,64\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "# for caltech it is 15420\n",
    "num_training_samples = 209\n",
    "# specify the number of output classes\n",
    "num_classes = 2\n",
    "# batch size for training\n",
    "mini_batch_size =  32\n",
    "# number of epochs\n",
    "epochs = 13\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be \n",
    "# initialized with pre-trained weights\n",
    "use_pretrained_model = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: DEMO-imageclassification-2018-07-31-23-47-38\n",
      "\n",
      "Input Data Location: {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-500842391574/train/', 'S3DataDistributionType': 'FullyReplicated'}\n",
      "CPU times: user 28 ms, sys: 0 ns, total: 28 ms\n",
      "Wall time: 29.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "#s3 = boto3.client('s3')\n",
    "# create unique job name \n",
    "job_name_prefix = 'DEMO-imageclassification'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output'.format(bucket, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"use_pretrained_model\": str(use_pretrained_model)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 360000\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"test\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/train/'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/test/'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: InProgress\n",
      "Training job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MXNet Estimator\n",
    "*SageMaker* provides built-in functionality to train and host [MXNet](http://mxnet.incubator.apache.org) and [Gluon](http://gluon.mxnet.io) models, using the `MXNet` class of the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk). Leveraging the MXNet Estimator drastically simplifies the handling of end-to-end training as well as deployment of custom MXNet models.\n",
    "\n",
    "Using the code (below), the model itself, the location of the training data and the Hyperparameters are applied to the MXNet Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MXNet Estimator\n",
    "mxnet_estimator = MXNet(\n",
    "    'model.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    output_path='s3://'+bucket,\n",
    "    hyperparameters={\n",
    "        'epochs': 2500,\n",
    "        'optmizer': 'sgd',\n",
    "        'learning_rate': 0.0075,\n",
    "        'batch_size': 64,\n",
    "        'threshold': 0.0019\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Job\n",
    "By calling the estimator's `fit()` method, with the location of the training data, *SageMaker* can start the model training using the configuration provided. After the training is successfully completed, the training results can be analyzed. Should the results prove that the model is optimal, It can then be deployed to *SageMaker's* hosting services.\n",
    ">**Note:** Make sure to note the Training Job Name as it will be used in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#                   Create a custom job name for current training run                        #\n",
    "#job_name = '<<Specific Training Job Name>>'                                                 #\n",
    "#mxnet_estimator.fit(input_data, job_name=job_name) # Fit the estimator to custom job name   #\n",
    "##############################################################################################\n",
    "\n",
    "# Automatically generate training job name\n",
    "mxnet_estimator.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 3 - Performance Analysis of the Trained Model.\n",
    "After a model has been trained and before it can be leveraged in production, it must be tested. This testing process typically takes the form of:\n",
    "1. **Analyzing the results from the training process:**\n",
    "    A good indication that the model performs well on the training data is to verify that the overall Training Error (Cost Function) decreases after every iteration of the forward propagation process.\n",
    "2. **Classification Accuracy (Training data set):**\n",
    "    While the Training Error provides a good indication of how well the Neural Network out probabilities agree with the observed labels, a common evaluation metric used for classification models sn the **Accuracy Score**. This metric generally summarizes the number of correct predictions the classifier has made as a ratio of all the predictions.\n",
    "3. **Classification Accuracy (Test/Validation data set):**\n",
    "    A good practice in machine learning is to create a subset of the training data keep it separate for testing. This is typically referred to as a hold-out, validation or test set. By testing how well the model performance against this data, further insight can be derived.\n",
    "    \n",
    "As can be seen from the output from training process above, the model learn the features of the training set to accurately classify the observed label. Additionally, when the model applies the optimized parameters to classify the test data, it achieves as overall accuracy of $80%$.\n",
    "\n",
    "Since the training function also captures these results to S3, the Cost/Error, training set Accuracy and test set Accuracy can be visualized as follows:\n",
    ">**Note**: Be sure to enter the name of the above SageMaker training job in `job_name` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and uncompress output results from model training\n",
    "job_name = '<<Enter Training Job Name>>'\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_name+'/output/output.tar.gz', '/tmp/output.tar.gz')\n",
    "tarfile.open('/tmp/output.tar.gz').extractall()\n",
    "with open('results.json') as j:\n",
    "    data = json.load(j)#, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# Format data for plotting\n",
    "costs = []\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for key, value in sorted(data.items()):#, key=lambda (k,v): (v, k)):\n",
    "    if 'epoch' in key:\n",
    "        for k, v in value.items():\n",
    "            if k == 'cost':\n",
    "                costs.append(v)\n",
    "            elif k == 'val_acc':\n",
    "                val_acc.append(v)\n",
    "            elif k == 'train_acc':\n",
    "                train_acc.append(v)\n",
    "    elif 'Start' in key:\n",
    "        start = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    elif 'End' in key:\n",
    "        end = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "val_acc = np.array(val_acc)\n",
    "train_acc = np.array(train_acc)\n",
    "costs = np.array(costs)\n",
    "delta = end - start\n",
    "print(\"Model Training Time: {} Minute(s)\".format(int(delta.total_seconds() / 60)))\n",
    "\n",
    "# Plot the Learning Curve\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)\n",
    "plt.grid(True, which='both')\n",
    "plt.plot(costs)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.ylabel('Cost / Accuracy')\n",
    "plt.xlabel('Epochs (in Hundreds)')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(['Cost', 'Training Accuracy', 'Validation Accuracy'])\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 4 - Performance Analysis of the Inference Endpoint.\n",
    "Testing the model against an image that is neither part of the training data or the testing data will provide realistic proof of it's performance in production. The following code cells demonstrate how the trained model performs against a selection of images that have pictures of cats as well as \"other\" pictures.\n",
    "\n",
    "To further simulate the predictive capabilities of the trained mode in a production environment, the `deploy()` method of the estimator is called to host the model on the *SageMaker* [hosting services](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html) which provides an HTTPS endpoint to provide classification inferences on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mxnet_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cells below show the pseudo production classification inferences on unseen image data by leveraging the hosted predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import transform\n",
    "\n",
    "# Get Classes\n",
    "classes = [\"non-cat\", \"cat\"]\n",
    "\n",
    "# Get Image files\n",
    "images = []\n",
    "for img_path in glob.glob('./images/*.jpeg'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(20.0,20.0))\n",
    "columns = 2\n",
    "for i, image in enumerate(images):\n",
    "    img = transform.resize(image, (64, 64), mode='constant').reshape((1, 64 * 64 * 3))\n",
    "    prediction = int(predictor.predict(img.tolist()))\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.title('Prediction = \"{}\" picture.'.format(classes[prediction]))\n",
    "    plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Next: Test the Production API\n",
    "Now that the model has been trained and validated for production, the **Data Science** part of the ML Pipeline can be integrated into the **DevOps** process. Refer back to the [README](../README.md) on the next steps.\n",
    ">**Note:** Make sure to remember the name of the training job, as it is necessary to complete the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix A: Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
